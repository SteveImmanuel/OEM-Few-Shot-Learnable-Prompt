{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoProcessor, CLIPModel\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch, open_clip\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "model.eval().to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_img_embed(image:Image) -> torch.Tensor: # 1 x 768\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(\"cuda\")\n",
    "    image_features = model.get_image_features(**inputs)\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/home/steve/Datasets/OpenEarthMap-FSS/testset/images'\n",
    "image_dir = '/home/steve/Datasets/OpenEarthMap-FSS/trainset/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_image_list = []\n",
    "s_image_features = []\n",
    "for file in os.listdir(source_dir):\n",
    "    img = Image.open(os.path.join(source_dir, file))\n",
    "    with torch.no_grad():\n",
    "        feat = extract_img_embed(img)\n",
    "    s_image_list.append(file)\n",
    "    s_image_features.append(feat)\n",
    "s_image_features = torch.cat(s_image_features, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_image_list = []\n",
    "t_image_features = []\n",
    "for file in os.listdir(image_dir):\n",
    "    img = Image.open(os.path.join(image_dir, file))\n",
    "    with torch.no_grad():\n",
    "        feat = extract_img_embed(img)\n",
    "    t_image_list.append(file)\n",
    "    t_image_features.append(feat)\n",
    "\n",
    "t_image_features = torch.cat(t_image_features, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = F.cosine_similarity(s_image_features.unsqueeze(1), t_image_features.unsqueeze(0), dim=2)\n",
    "print(sim_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/home/steve/Datasets/OpenEarthMap-FSS/trainset/similarity-vit'\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each row sort the similarity matrix and get the top k\n",
    "for s_i in range(sim_matrix.shape[0]):\n",
    "    sim_row = sim_matrix[s_i]\n",
    "    sim_row, sim_row_indices = torch.sort(sim_row, descending=True)\n",
    "\n",
    "    name = s_image_list[s_i].split('.')[0]\n",
    "    os.makedirs(os.path.join(out_dir, name), exist_ok=True)\n",
    "    for i in range(10):\n",
    "        img = Image.open(os.path.join(image_dir, t_image_list[sim_row_indices[i]]))\n",
    "        img.save(os.path.join(out_dir, name, f'{i+1}_sim_{sim_row[i]:.3f}_{t_image_list[sim_row_indices[i]]}'))\n",
    "    #save the original image too\n",
    "    img = Image.open(os.path.join(source_dir, s_image_list[s_i]))\n",
    "    img.save(os.path.join(out_dir, name, f'0_{s_image_list[s_i]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_json_dict = {}\n",
    "\n",
    "for s_i in range(sim_matrix.shape[0]):\n",
    "    sim_row = sim_matrix[s_i]\n",
    "    sim_row, sim_row_indices = torch.sort(sim_row, descending=True)\n",
    "\n",
    "    name = s_image_list[s_i]\n",
    "    out_json_dict[name] = []\n",
    "    for i in range(10):\n",
    "        out_json_dict[name].append(t_image_list[sim_row_indices[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('mapping_remoteclip.json', 'w') as f:\n",
    "    json.dump(out_json_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
