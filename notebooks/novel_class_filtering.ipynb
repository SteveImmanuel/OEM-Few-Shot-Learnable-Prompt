{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steve/miniconda3/envs/seg/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoProcessor, CLIPModel\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "model.eval().to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_img_embed(image:Image) -> torch.Tensor: # 1 x 768\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(\"cuda\")\n",
    "    image_features = model.get_image_features(**inputs)\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/home/steve/Datasets/OpenEarthMap-FSS/temptest/images'\n",
    "supportset_dir = '/home/steve/Datasets/OpenEarthMap-FSS/temptest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 768])\n"
     ]
    }
   ],
   "source": [
    "s_image_list = []\n",
    "s_image_features = []\n",
    "for file in sorted(os.listdir(source_dir)):\n",
    "    img = Image.open(os.path.join(source_dir, file))\n",
    "    with torch.no_grad():\n",
    "        feat = extract_img_embed(img)\n",
    "    s_image_list.append(file)\n",
    "    s_image_features.append(feat)\n",
    "s_image_features = torch.cat(s_image_features, dim=0)\n",
    "print(s_image_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sset_image_features = {}\n",
    "for i in range(8, 12):\n",
    "    t_image_list = []\n",
    "    t_image_features = []\n",
    "    for file in os.listdir(os.path.join(supportset_dir, str(i), 'images')):\n",
    "        img = Image.open(os.path.join(supportset_dir, str(i), 'images', file))\n",
    "        with torch.no_grad():\n",
    "            feat = extract_img_embed(img)\n",
    "        t_image_list.append(file)\n",
    "        t_image_features.append(feat)\n",
    "\n",
    "    t_image_features = torch.cat(t_image_features, dim=0)\n",
    "    sset_image_features[i] = {}\n",
    "    sset_image_features[i]['feat'] = t_image_features\n",
    "    sset_image_features[i]['list'] = t_image_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = {\n",
    "    8: [0.65, 0.7],\n",
    "    9: [0.72, 0.82],\n",
    "    10: [0.7, 0.73],\n",
    "    11: [0.67, 0.8]\n",
    "}\n",
    "\n",
    "out = {i: {'filter_list': [], 'force_overlay': []} for i in range(8, 12)}\n",
    "for i in range(8, 12):\n",
    "    sset_feat = sset_image_features[i]['feat']\n",
    "    sim_matrix = F.cosine_similarity(sset_feat.unsqueeze(1), s_image_features.unsqueeze(0), dim=2)\n",
    "    for j in range(len(s_image_list)):\n",
    "        if sim_matrix[:, j].mean().item() >= threshold[i][1]:\n",
    "            out[i]['force_overlay'].append(s_image_list[j])\n",
    "            # print('overlay', i, j, s_image_list[j], sim_matrix[:, j], sim_matrix[:, j].mean().item())\n",
    "        elif sim_matrix[:, j].mean().item() <= threshold[i][0]:\n",
    "            out[i]['filter_list'].append(s_image_list[j])\n",
    "            # print('exclude', i, j, s_image_list[j], sim_matrix[:, j], sim_matrix[:, j].mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('filter.json', 'w') as f:\n",
    "    json.dump(out, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
